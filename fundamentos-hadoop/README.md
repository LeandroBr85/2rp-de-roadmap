ecossistema hadoop >> 
The Hadoop ecosystem frameworks and applications have several overarching themes and goals. They provide scalability to store large volumes of data on commodity hardware,  Hadoop ecosystem then, has ability to handle different data types for any given type of data.allow multiple jobs to execute simultaneously.

More than 100 open-source projects for big data and this number continues to grow.

layer diagram can be organized vertically based on the interface. Low level interfaces, so storage and scheduling, on the bottom. And high level languages and interactivity at the top.

hdfs >> hadoop distributed file system

yarn >> the scheduler and resource manager -- ( YARN is used at Yahoo to schedule jobs across 40,000 servers.)

MapReduce >> a programming model for processing big data.

Hive >> Hive was created at Facebook to issue SQL-like queries using MapReduce on their data in HDFS.

Pig >> Was created at Yahoo to model data flow based programs using MapReduce.

Giraph >> Was built for processing large-scale graphs efficiently 

Cassandra, MongoDB, and HBase >> NoSQL projects.

Zookeeper >> Centralized management system for synchronization, configuration and to ensure high availability.

MapReduce >> it relies on YARN to schedule and execute parallel processing over the distributed file blocks in HDFS.
 




